"""
ğŸ“˜ ë³´í—˜ ì•½ê´€ RAG ì±—ë´‡ - Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤
"""

import streamlit as st
import os
import time
from dotenv import load_dotenv
from rag_chatbot import RAGChatbot
import json

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = None
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'initialized' not in st.session_state:
        st.session_state.initialized = False

def initialize_chatbot():
    """ì±—ë´‡ ì´ˆê¸°í™”"""
    try:
        with st.spinner("ğŸ¤– RAG ì±—ë´‡ì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘..."):
            chatbot = RAGChatbot()
            count = chatbot.get_collection_info()
            
            if count == 0:
                st.error("âŒ ë²¡í„° ì €ì¥ì†Œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.")
                return None
            
            st.session_state.chatbot = chatbot
            st.session_state.initialized = True
            st.success(f"âœ… ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ! (ì´ {count}ê°œ ë¬¸ì„œ)")
            
    except Exception as e:
        st.error(f"âŒ ì±—ë´‡ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return None

def main():
    st.set_page_config(
        page_title="ë³´í—˜ ì•½ê´€ RAG ì±—ë´‡",
        page_icon="ğŸ“˜",
        layout="wide"
    )
    
    # CSS ìŠ¤íƒ€ì¼ ì¶”ê°€ (GPT ìŠ¤íƒ€ì¼ ì±„íŒ… UI)
    st.markdown("""
    <style>
    /* ì±„íŒ… ì˜ì—­ ê³ ì • ë†’ì´ ë° ìŠ¤í¬ë¡¤ */
    .chat-container {
        height: calc(100vh - 250px);
        overflow-y: auto;
        overflow-x: hidden;
        padding: 1rem;
        display: flex;
        flex-direction: column;
    }
    
    /* ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .stChatMessage {
        margin-bottom: 1rem;
    }
    
    /* ì…ë ¥ì°½ í•˜ë‹¨ ê³ ì • */
    .stChatFloatingInputContainer {
        position: sticky;
        bottom: 0;
        z-index: 999;
        background-color: var(--background-color);
        padding: 1rem 0;
    }
    
    /* ë©”ì¸ ë ˆì´ì•„ì›ƒ ì¡°ì • */
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
    }
    
    /* í—¤ë” ê³ ì • */
    .stApp > header {
        position: fixed;
        top: 0;
        z-index: 1000;
    }
    
    /* ìŠ¤í¬ë¡¤ë°” ìŠ¤íƒ€ì¼ */
    .chat-container::-webkit-scrollbar {
        width: 8px;
    }
    
    .chat-container::-webkit-scrollbar-track {
        background: #f1f1f1;
    }
    
    .chat-container::-webkit-scrollbar-thumb {
        background: #888;
        border-radius: 4px;
    }
    
    .chat-container::-webkit-scrollbar-thumb:hover {
        background: #555;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # í—¤ë”
    st.title("ğŸ“˜ ë³´í—˜ ì•½ê´€ RAG ì±—ë´‡")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # API í‚¤ í™•ì¸
        if not os.getenv('OPENAI_API_KEY'):
            st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸš€ ì±—ë´‡ ì´ˆê¸°í™”", type="primary"):
            initialize_chatbot()
        
        # ìƒíƒœ í‘œì‹œ
        if st.session_state.initialized:
            st.success("âœ… ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ")
        else:
            st.warning("âš ï¸ ì±—ë´‡ ì´ˆê¸°í™” í•„ìš”")
        
        st.markdown("---")
        
        # ì‚¬ìš©ë²•
        st.header("ğŸ“– ì‚¬ìš©ë²•")
        st.markdown("""
        1. **ì´ˆê¸°í™”**: ì±—ë´‡ ì´ˆê¸°í™” ë²„íŠ¼ í´ë¦­
        2. **ì§ˆë¬¸**: ì•„ë˜ ì…ë ¥ì°½ì— ì§ˆë¬¸ ì…ë ¥
        3. **ë‹µë³€**: AIê°€ ì•½ê´€ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
        4. **ì¶œì²˜**: ë‹µë³€ì— í˜ì´ì§€ ë²ˆí˜¸ í‘œì‹œ
        """)
        
        # ì˜ˆì‹œ ì§ˆë¬¸
        st.header("ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸")
        example_questions = [
            "ë³´í—˜ê¸ˆ ì§€ê¸‰ ì‚¬ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "ë³´í—˜ë£ŒëŠ” ì–´ë–»ê²Œ ë‚©ì…í•˜ë‚˜ìš”?",
            "ë©´ì±… ì‚¬í•­ì´ ìˆë‚˜ìš”?",
            "ë³´í—˜ ê¸°ê°„ì€ ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?",
            "í•´ì§€ ì‹œ í™˜ê¸‰ê¸ˆì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
        ]
        
        for question in example_questions:
            if st.button(question, key=f"example_{question}"):
                st.session_state.user_input = question
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if not st.session_state.initialized:
            st.info("ğŸ‘† ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ ì±—ë´‡ì„ ì´ˆê¸°í™”í•˜ì„¸ìš”.")
        
        # ì±„íŒ… ì˜ì—­ (ê³ ì • ë†’ì´, ìŠ¤í¬ë¡¤ ê°€ëŠ¥)
        chat_area = st.container(height=600)
        
        with chat_area:
            # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ (ìœ„ì—ì„œ ì•„ë˜ë¡œ)
            if st.session_state.chat_history:
                for chat in st.session_state.chat_history:
                    with st.chat_message("user"):
                        st.write(chat["query"])
                    
                    with st.chat_message("assistant"):
                        st.write(chat["answer"])
                        
                        # ì¶œì²˜ ì •ë³´
                        if chat["sources"]:
                            with st.expander(f"ğŸ“š ì°¸ê³  ë¬¸ì„œ ({len(chat['sources'])}ê°œ)"):
                                for j, source in enumerate(chat["sources"], 1):
                                    st.write(f"**ë¬¸ì„œ {j}** (í˜ì´ì§€ {source['page']})")
                                    st.write(source["content"])
                                    st.write("---")
        
        # ì‚¬ìš©ì ì…ë ¥ (í•˜ë‹¨ ê³ ì • - Streamlitì˜ chat_inputì´ ìë™ìœ¼ë¡œ í•˜ë‹¨ì— ë°°ì¹˜ë¨)
        if st.session_state.initialized:
            user_input = st.chat_input("ë³´í—˜ ì•½ê´€ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”...", key="chat_input")
            
            if user_input:
                # ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ
                with chat_area:
                    with st.chat_message("user"):
                        st.write(user_input)
                
                # AI ë‹µë³€ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
                with chat_area:
                    with st.chat_message("assistant"):
                        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ ì»¨í…Œì´ë„ˆ
                        message_placeholder = st.empty()
                        sources_placeholder = st.empty()
                        
                        # ì´ˆê¸° ë¡œë”© ë©”ì‹œì§€
                        message_placeholder.markdown("ğŸ¤” ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘...")
                        
                        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
                        full_answer = ""
                        final_sources = []
                        streaming_started = False
                        
                        for chunk in st.session_state.chatbot.chat_streaming(user_input):
                            if not chunk["done"]:
                                # ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
                                if not streaming_started:
                                    streaming_started = True
                                    message_placeholder.empty()  # ë¡œë”© ë©”ì‹œì§€ ì œê±°
                                
                                # ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹µë³€ ì—…ë°ì´íŠ¸ (íƒ€ì´í•‘ íš¨ê³¼)
                                full_answer = chunk["answer"]
                                message_placeholder.markdown(full_answer + "â–Œ")
                                time.sleep(0.01)  # ë¶€ë“œëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì§§ì€ ì§€ì—°
                            else:
                                # ìµœì¢… ì™„ì„±ëœ ì‘ë‹µ
                                full_answer = chunk["answer"]
                                final_sources = chunk["sources"]
                                message_placeholder.markdown(full_answer)
                        
                        # ì¶œì²˜ ì •ë³´ í‘œì‹œ
                        if final_sources:
                            with sources_placeholder.expander(f"ğŸ“š ì°¸ê³  ë¬¸ì„œ ({len(final_sources)}ê°œ)"):
                                for i, source in enumerate(final_sources, 1):
                                    st.write(f"**ë¬¸ì„œ {i}** (í˜ì´ì§€ {source['page']})")
                                    st.write(source["content"])
                                    st.write("---")
                
                # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.chat_history.append({
                    "query": user_input,
                    "answer": full_answer,
                    "sources": final_sources
                })
                
                # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆ ë©”ì‹œì§€ í‘œì‹œ
                st.rerun()
    
    with col2:
        st.header("ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
        
        if st.session_state.initialized:
            # ì €ì¥ì†Œ ì •ë³´
            st.subheader("ğŸ“š ë²¡í„° ì €ì¥ì†Œ")
            count = st.session_state.chatbot.get_collection_info()
            st.metric("ì´ ë¬¸ì„œ ìˆ˜", count)
            
            # ì²˜ë¦¬ëœ ë°ì´í„° ì •ë³´
            if os.path.exists("processed_data/ì•½ê´€_processed.json"):
                with open("processed_data/ì•½ê´€_processed.json", 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                st.subheader("ğŸ“„ ì²˜ë¦¬ëœ PDF")
                st.metric("ì´ í˜ì´ì§€", len(data))
                
                total_tables = sum(page.get("tables_count", 0) for page in data)
                st.metric("ì´ í‘œ", total_tables)
            
            # ì±„íŒ… í†µê³„
            st.subheader("ğŸ’¬ ì±„íŒ… í†µê³„")
            st.metric("ì´ ëŒ€í™” ìˆ˜", len(st.session_state.chat_history))
            
        else:
            st.info("ì±—ë´‡ì„ ì´ˆê¸°í™”í•˜ë©´ ì‹œìŠ¤í…œ ì •ë³´ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ—‘ï¸ ì±„íŒ… ê¸°ë¡ ì‚­ì œ"):
            st.session_state.chat_history = []
            st.rerun()

if __name__ == "__main__":
    main()

