"""
ğŸ” Vector Store ì„±ëŠ¥ ì¸¡ì • ë²¤ì¹˜ë§ˆí¬
ì„ë² ë”© ìƒì„±, ì €ì¥, ê²€ìƒ‰ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
"""

import time
import sys
import io
import os
import json
import tracemalloc
from typing import List, Dict
from vector_store import VectorStore
from dotenv import load_dotenv

# Windows ì½˜ì†”ì—ì„œ í•œê¸€ ì¶œë ¥ì„ ìœ„í•œ ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

load_dotenv()

class PerformanceBenchmark:
    """ì„±ëŠ¥ ì¸¡ì • í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.results = {}
        
    def measure_embedding_speed(self, vector_store: VectorStore, test_texts: List[str]):
        """ì„ë² ë”© ìƒì„± ì†ë„ ì¸¡ì •"""
        print("\n" + "="*60)
        print("ğŸ“Š ì„ë² ë”© ìƒì„± ì†ë„ ì¸¡ì •")
        print("="*60)
        
        start_time = time.time()
        
        # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± ì¸¡ì •
        total_chars = 0
        for text in test_texts:
            # ì„ë² ë”© í•¨ìˆ˜ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì†ë„ ì¸¡ì •
            _ = vector_store.embedding_function([text])
            total_chars += len(text)
        
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        avg_time_per_text = elapsed_time / len(test_texts)
        chars_per_second = total_chars / elapsed_time if elapsed_time > 0 else 0
        
        print(f"âœ… ì´ í…ìŠ¤íŠ¸ ìˆ˜: {len(test_texts)}ê°œ")
        print(f"âœ… ì´ ë¬¸ì ìˆ˜: {total_chars:,}ì")
        print(f"âœ… ì´ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
        print(f"âœ… í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time_per_text*1000:.2f}ms/í…ìŠ¤íŠ¸")
        print(f"âœ… ì²˜ë¦¬ ì†ë„: {chars_per_second:.0f}ì/ì´ˆ")
        print(f"âœ… ì²˜ë¦¬ëŸ‰: {len(test_texts)/elapsed_time:.2f}í…ìŠ¤íŠ¸/ì´ˆ")
        
        self.results['embedding'] = {
            'total_texts': len(test_texts),
            'total_chars': total_chars,
            'total_time': elapsed_time,
            'avg_time_per_text': avg_time_per_text,
            'chars_per_second': chars_per_second,
            'throughput': len(test_texts)/elapsed_time
        }
        
        return elapsed_time
    
    def measure_storage_speed(self, vector_store: VectorStore, chunks: List[Dict]):
        """ë²¡í„° DB ì €ì¥ ì†ë„ ì¸¡ì •"""
        print("\n" + "="*60)
        print("ğŸ’¾ ë²¡í„° DB ì €ì¥ ì†ë„ ì¸¡ì •")
        print("="*60)
        
        # ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘
        tracemalloc.start()
        start_memory = tracemalloc.get_traced_memory()[0]
        
        start_time = time.time()
        
        # ì‹¤ì œ ì €ì¥ ìˆ˜í–‰
        vector_store.store_in_vector_db(chunks)
        
        end_time = time.time()
        current_memory, peak_memory = tracemalloc.get_traced_memory()
        tracemalloc.stop()
        
        elapsed_time = end_time - start_time
        memory_used = (current_memory - start_memory) / (1024 * 1024)  # MB
        peak_memory_mb = peak_memory / (1024 * 1024)  # MB
        
        chunks_per_second = len(chunks) / elapsed_time if elapsed_time > 0 else 0
        
        print(f"âœ… ì´ ì²­í¬ ìˆ˜: {len(chunks):,}ê°œ")
        print(f"âœ… ì´ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
        print(f"âœ… ì €ì¥ ì†ë„: {chunks_per_second:.2f}ì²­í¬/ì´ˆ")
        print(f"âœ… í‰ê·  ì²˜ë¦¬ ì‹œê°„: {elapsed_time/len(chunks)*1000:.2f}ms/ì²­í¬")
        print(f"âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_used:.2f}MB")
        print(f"âœ… ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {peak_memory_mb:.2f}MB")
        
        self.results['storage'] = {
            'total_chunks': len(chunks),
            'total_time': elapsed_time,
            'chunks_per_second': chunks_per_second,
            'avg_time_per_chunk': elapsed_time/len(chunks),
            'memory_used_mb': memory_used,
            'peak_memory_mb': peak_memory_mb
        }
        
        return elapsed_time
    
    def measure_search_speed(self, vector_store: VectorStore, test_queries: List[str], top_k: int = 5):
        """ê²€ìƒ‰ ì†ë„ ì¸¡ì •"""
        print("\n" + "="*60)
        print("ğŸ” ê²€ìƒ‰ ì†ë„ ì¸¡ì •")
        print("="*60)
        
        search_times = []
        results_list = []
        
        for query in test_queries:
            start_time = time.time()
            results = vector_store.search_similar(query, top_k=top_k)
            end_time = time.time()
            
            elapsed_time = end_time - start_time
            search_times.append(elapsed_time)
            results_list.append(results)
        
        avg_search_time = sum(search_times) / len(search_times)
        min_search_time = min(search_times)
        max_search_time = max(search_times)
        queries_per_second = 1 / avg_search_time if avg_search_time > 0 else 0
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìˆ˜: {len(test_queries)}ê°œ")
        print(f"âœ… í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_search_time*1000:.2f}ms")
        print(f"âœ… ìµœì†Œ ê²€ìƒ‰ ì‹œê°„: {min_search_time*1000:.2f}ms")
        print(f"âœ… ìµœëŒ€ ê²€ìƒ‰ ì‹œê°„: {max_search_time*1000:.2f}ms")
        print(f"âœ… ê²€ìƒ‰ ì²˜ë¦¬ëŸ‰: {queries_per_second:.2f}ì¿¼ë¦¬/ì´ˆ")
        print(f"âœ… ê²°ê³¼ ìˆ˜: {top_k}ê°œ/ì¿¼ë¦¬")
        
        # ê²€ìƒ‰ í’ˆì§ˆ í™•ì¸
        total_results = sum(len(r) for r in results_list)
        avg_results = total_results / len(results_list)
        print(f"âœ… í‰ê·  ë°˜í™˜ ê²°ê³¼: {avg_results:.1f}ê°œ")
        
        self.results['search'] = {
            'total_queries': len(test_queries),
            'avg_search_time': avg_search_time,
            'min_search_time': min_search_time,
            'max_search_time': max_search_time,
            'queries_per_second': queries_per_second,
            'top_k': top_k,
            'avg_results_per_query': avg_results
        }
        
        return search_times
    
    def measure_collection_info(self, vector_store: VectorStore):
        """ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ"""
        print("\n" + "="*60)
        print("ğŸ“Š ì»¬ë ‰ì…˜ ì •ë³´")
        print("="*60)
        
        start_time = time.time()
        count = vector_store.get_collection_info()
        end_time = time.time()
        
        query_time = end_time - start_time
        
        print(f"âœ… ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹œê°„: {query_time*1000:.2f}ms")
        
        self.results['collection_info'] = {
            'document_count': count,
            'query_time': query_time
        }
    
    def print_summary(self):
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“ˆ ì„±ëŠ¥ ì¸¡ì • ìš”ì•½")
        print("="*60)
        
        if 'embedding' in self.results:
            emb = self.results['embedding']
            print(f"\n[ì„ë² ë”© ìƒì„±]")
            print(f"   ì²˜ë¦¬ëŸ‰: {emb['throughput']:.2f}í…ìŠ¤íŠ¸/ì´ˆ")
            print(f"   ì†ë„: {emb['chars_per_second']:.0f}ì/ì´ˆ")
        
        if 'storage' in self.results:
            st = self.results['storage']
            print(f"\n[ë²¡í„° DB ì €ì¥]")
            print(f"   ì²˜ë¦¬ëŸ‰: {st['chunks_per_second']:.2f}ì²­í¬/ì´ˆ")
            print(f"   ë©”ëª¨ë¦¬: {st['peak_memory_mb']:.2f}MB")
        
        if 'search' in self.results:
            sr = self.results['search']
            print(f"\n[ê²€ìƒ‰ ì„±ëŠ¥]")
            print(f"   í‰ê·  ê²€ìƒ‰ ì‹œê°„: {sr['avg_search_time']*1000:.2f}ms")
            print(f"   ì²˜ë¦¬ëŸ‰: {sr['queries_per_second']:.2f}ì¿¼ë¦¬/ì´ˆ")
        
        if 'collection_info' in self.results:
            ci = self.results['collection_info']
            print(f"\n[ì»¬ë ‰ì…˜ ì •ë³´]")
            print(f"   ì´ ë¬¸ì„œ ìˆ˜: {ci['document_count']:,}ê°œ")
        
        print("\n" + "="*60)
    
    def save_results(self, filename: str = "benchmark_results.json"):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, indent=2, ensure_ascii=False)
            print(f"\nâœ… ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼ê°€ '{filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"\nâŒ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")


def create_test_data():
    """í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±"""
    # ìƒ˜í”Œ í…ìŠ¤íŠ¸ë“¤
    test_texts = [
        "ë³´í—˜ê¸ˆ ì§€ê¸‰ ì‚¬ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ë³´í—˜ë£ŒëŠ” ì–´ë–»ê²Œ ë‚©ì…í•˜ë‚˜ìš”?",
        "ë©´ì±… ì‚¬í•­ì´ ìˆë‚˜ìš”?",
        "ë³´í—˜ ê¸°ê°„ì€ ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?",
        "í•´ì§€ ì‹œ í™˜ê¸‰ê¸ˆì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "ë³´í—˜ ê°€ì… ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë³´í—˜ë£Œ ë‚©ì… ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ë³´í—˜ê¸ˆ ì²­êµ¬ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "ë³´í—˜ ê³„ì•½ í•´ì§€ ì‹œ ìœ ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë³´í—˜ ê³„ì•½ ê°±ì‹ ì€ ì–¸ì œ í•˜ë‚˜ìš”?",
    ]
    
    # ë” ê¸´ í…ìŠ¤íŠ¸ ìƒ˜í”Œ (ì‹¤ì œ ë¬¸ì„œì™€ ìœ ì‚¬í•˜ê²Œ)
    long_texts = [
        "ë³¸ ì•½ê´€ì€ ê´€ê³„ ë²•ë ¹ ë° ë‚´ë¶€í†µì œê¸°ì¤€ì— ë”°ë¥¸ ì ˆì°¨ë¥¼ ê±°ì³ ì œê³µë©ë‹ˆë‹¤. ë³´í—˜ê³„ì•½ì€ ë³´í—˜íšŒì‚¬ì™€ ê³„ì•½ì ê°„ì— ì²´ê²°ë˜ë©°, ë³´í—˜ë£Œ ë‚©ì… ë° ë³´í—˜ê¸ˆ ì§€ê¸‰ì— ê´€í•œ ì‚¬í•­ì„ ê·œì •í•©ë‹ˆë‹¤.",
        "ë³´í—˜ê¸ˆ ì§€ê¸‰ ì‚¬ìœ ëŠ” ë³´í—˜ê³„ì•½ì—ì„œ ì •í•œ ì‚¬ê³  ë°œìƒ ì‹œ ì¸ì •ë©ë‹ˆë‹¤. ì§€ê¸‰ ì ˆì°¨ëŠ” ë³´í—˜ê¸ˆ ì²­êµ¬ì„œì™€ ê´€ë ¨ ì„œë¥˜ë¥¼ ì œì¶œí•œ í›„ ì‹¬ì‚¬ ê³¼ì •ì„ ê±°ì³ ì§€ê¸‰ë©ë‹ˆë‹¤.",
        "ë³´í—˜ë£ŒëŠ” ì›”ë‚©, ë¶„ê¸°ë‚©, ë°˜ê¸°ë‚©, ì—°ë‚© ë°©ì‹ìœ¼ë¡œ ë‚©ì…í•  ìˆ˜ ìˆìœ¼ë©°, ê³„ì•½ì„œì— ëª…ì‹œëœ ë‚©ì… ê¸°ì¼ê¹Œì§€ ë‚©ì…í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤. ë‚©ì… ì—°ì²´ ì‹œì—ëŠ” ê³„ì•½ í•´ì§€ ë“± ë¶ˆì´ìµì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    ] * 10  # ì´ 30ê°œ
    
    return test_texts + long_texts


def main():
    """ë©”ì¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print("ğŸš€ Vector Store ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    print("="*60)
    
    # ë²¤ì¹˜ë§ˆí¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    benchmark = PerformanceBenchmark()
    
    # 1. ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” (ì„±ëŠ¥ ì¸¡ì •ìš© - ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì—†ì´)
    print("\n[1ë‹¨ê³„] ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì¤‘...")
    vector_store = VectorStore(collection_name="insurance_terms_benchmark")
    
    # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    print("\n[2ë‹¨ê³„] í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    test_texts = create_test_data()
    print(f"   - í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸: {len(test_texts)}ê°œ")
    
    # 3. ì„ë² ë”© ìƒì„± ì†ë„ ì¸¡ì •
    print("\n[3ë‹¨ê³„] ì„ë² ë”© ìƒì„± ì†ë„ ì¸¡ì • ì¤‘...")
    benchmark.measure_embedding_speed(vector_store, test_texts[:10])  # ì²˜ìŒ 10ê°œë§Œ
    
    # 4. ì‹¤ì œ ë°ì´í„°ë¡œ ì €ì¥ ì†ë„ ì¸¡ì • (ì„ íƒì )
    print("\n[4ë‹¨ê³„] ì‹¤ì œ ë°ì´í„° ì €ì¥ ì†ë„ ì¸¡ì • ì¤‘...")
    json_files = [
        "processed_data/all_pdfs_pages.json",
        "processed_data/ì•½ê´€_pages.json"
    ]
    
    json_file = None
    for file_path in json_files:
        if os.path.exists(file_path):
            json_file = file_path
            break
    
    if json_file:
        print(f"   ë°ì´í„° íŒŒì¼ ë°œê²¬: {json_file}")
        pages_data = vector_store.load_processed_data(json_file)
        
        if pages_data:
            # ì¼ë¶€ í˜ì´ì§€ë§Œ ì‚¬ìš© (ì „ì²´ ì¸¡ì •ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)
            sample_pages = pages_data[:10]  # ì²˜ìŒ 10í˜ì´ì§€ë§Œ
            print(f"   ìƒ˜í”Œ í˜ì´ì§€ ìˆ˜: {len(sample_pages)}ê°œ (ì „ì²´ {len(pages_data)}ê°œ ì¤‘)")
            
            chunks = vector_store.process_all_pages(sample_pages)
            if chunks:
                benchmark.measure_storage_speed(vector_store, chunks)
        else:
            print("   âš ï¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ - ì €ì¥ ì†ë„ ì¸¡ì • ê±´ë„ˆëœ€")
    else:
        print("   âš ï¸ ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ ì—†ìŒ - ì €ì¥ ì†ë„ ì¸¡ì • ê±´ë„ˆëœ€")
        print("   (ì‹¤ì œ ì¸¡ì •ì„ ì›í•˜ì‹œë©´ ë¨¼ì € pdf_preprocessor.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”)")
    
    # 5. ê²€ìƒ‰ ì†ë„ ì¸¡ì •
    print("\n[5ë‹¨ê³„] ê²€ìƒ‰ ì†ë„ ì¸¡ì • ì¤‘...")
    test_queries = [
        "ë³´í—˜ê¸ˆ ì§€ê¸‰",
        "ë³´í—˜ë£Œ ë‚©ì…",
        "ê³„ì•½ í•´ì§€",
        "ë©´ì±… ì‚¬í•­",
        "ë³´í—˜ ê¸°ê°„",
        "í™˜ê¸‰ê¸ˆ",
        "ë³´í—˜ ê°€ì… ì¡°ê±´",
        "ë³´í—˜ê¸ˆ ì²­êµ¬",
    ]
    benchmark.measure_search_speed(vector_store, test_queries, top_k=5)
    
    # 6. ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ
    benchmark.measure_collection_info(vector_store)
    
    # 7. ìš”ì•½ ë° ê²°ê³¼ ì €ì¥
    benchmark.print_summary()
    benchmark.save_results()
    
    print("\nâœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
