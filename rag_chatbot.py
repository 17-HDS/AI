"""
ğŸ“˜ RAGChatbot (ChromaDB ê¸°ë°˜ ë‹¨ì¼ ë²„ì „)
"""

import os
from dotenv import load_dotenv
import chromadb
from openai import OpenAI

load_dotenv()


class RAGChatbot:
    def __init__(self, db_path: str = "./chroma_db", collection_name: str = "insurance_terms"):
        """RAG ì±—ë´‡ ì´ˆê¸°í™”"""
        self.client = chromadb.PersistentClient(path=db_path)

        # ì»¬ë ‰ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)
        self.collection = self.client.get_collection(collection_name)

        # OpenAI í´ë¼ì´ì–¸íŠ¸
        self.model = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        # ë§ˆì§€ë§‰ ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶œì²˜ ì €ì¥
        self.last_sources = []

    # -----------------------------------------------------
    # ğŸ” ì»¬ë ‰ì…˜ ì •ë³´
    # -----------------------------------------------------
    def get_collection_info(self):
        """ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜"""
        try:
            count = self.collection.count()
            return count
        except Exception:
            return 0

    # -----------------------------------------------------
    # ğŸ” ë¬¸ì„œ ê²€ìƒ‰
    # -----------------------------------------------------
    def search_similar_docs(self, query: str, top_k: int = 5) -> str:
        """ChromaDBì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k
        )

        if not results["documents"]:
            self.last_sources = []
            return ""

        docs = results["documents"][0]
        metadatas = results["metadatas"][0]

        self.last_sources = [
            {
                "content": doc,
                "page": meta.get("page", "?"),
                "source": meta.get("source", "unknown")
            }
            for doc, meta in zip(docs, metadatas)
        ]

        return "\n\n".join(docs)

    # -----------------------------------------------------
    # ğŸ’¬ ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„±
    # -----------------------------------------------------
    def chat_streaming(self, query: str):
        """OpenAI ëª¨ë¸ì„ ì´ìš©í•´ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
        try:
            context = self.search_similar_docs(query)

            if not context:
                yield {
                    "answer": "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.",
                    "done": True,
                    "sources": []
                }
                return

            prompt = (
                "ë‹¤ìŒì€ ë³´í—˜ ì•½ê´€ì˜ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤. "
                "ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n\n"
                f"{context}\n\n"
                f"ì‚¬ìš©ì ì§ˆë¬¸: {query}"
            )

            # GPT ëª¨ë¸ ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
            stream = self.model.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë³´í—˜ ì•½ê´€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                stream=True,
            )

            answer = ""

            for chunk in stream:
                delta = chunk.choices[0].delta.content if chunk.choices[0].delta else ""
                if delta:
                    answer += delta
                    yield {"answer": answer, "done": False}

            # ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ
            yield {"answer": answer, "done": True, "sources": self.last_sources}

        except Exception as e:
            yield {
                "answer": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "done": True,
                "sources": []
            }
